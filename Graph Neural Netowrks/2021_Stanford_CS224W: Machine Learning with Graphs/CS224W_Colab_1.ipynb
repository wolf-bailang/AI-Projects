{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"CS224W_Colab_1.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AfugdGpiS2tz"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XuXWJLEm2UWS"},"source":["# **CS224W - Colab 1**"]},{"cell_type":"markdown","metadata":{"id":"8gzsP50bF6Gb"},"source":["In this Colab, we will write a full pipeline for **learning node embeddings**.\n","We will go through the following 3 steps.  \n","在这个 Colab 中，我们将编写一个完整的管道来学习节点嵌入。 我们将经历以下 3 个步骤。\n","\n","To start, we will load a classic graph in network science, the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). We will explore multiple graph statistics for that graph.  \n","首先，我们将加载网络科学中的经典图，即空手道俱乐部网络。 我们将探索该图的多个图统计信息。\n","\n","We will then work together to transform the graph structure into a PyTorch tensor, so that we can perform machine learning over the graph.  \n","然后我们将共同将图结构转换为 PyTorch 张量，以便我们可以对图执行机器学习。\n","\n","Finally, we will finish the first learning algorithm on graphs: a node embedding model. For simplicity, our model here is simpler than DeepWalk / node2vec algorithms taught in the lecture. But it's still rewarding and challenging, as we will write it from scratch via PyTorch.  \n","最后，我们将完成第一个图学习算法：节点嵌入模型。 为简单起见，我们这里的模型比讲座中教授的 DeepWalk / node2vec 算法简单。 但它仍然是有益的和具有挑战性的，因为我们将通过 PyTorch 从头开始编写它。\n","\n","Now let's get started!  \n","现在让我们开始吧！\n","\n","**Note**: Make sure to **sequentially run all the cells**, so that the intermediate variables / packages will carry over to the next cell  \n","注意：确保顺序运行所有单元格，以便中间变量/包会延续到下一个单元格"]},{"cell_type":"markdown","metadata":{"id":"Nwwq0nSdmsOL"},"source":["# 1 Graph Basics\n","To start, we will load a classic graph in network science, the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). We will explore multiple graph statistics for that graph.  \n","首先，我们将加载网络科学中的经典图，即空手道俱乐部网络。 我们将探索该图的多个图统计信息。"]},{"cell_type":"markdown","metadata":{"id":"FDkpByYYfSzb"},"source":["## Setup\n","We will heavily use NetworkX in this Colab."]},{"cell_type":"code","metadata":{"id":"VWPkJjPAfVNW"},"source":["import networkx as nx"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VqUnYT5qUZYh"},"source":["## Zachary's karate club network\n","\n","The [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) is a graph describes a social network of 34 members of a karate club and documents links between members who interacted outside the club.  \n","空手道俱乐部网络是一个图表，描述了一个空手道俱乐部的 34 名成员的社交网络，并记录了在俱乐部外互动的成员之间的链接。"]},{"cell_type":"code","metadata":{"id":"VIETqEfrfy5Y"},"source":["G = nx.karate_club_graph()\n","\n","# G is an undirected graph\n","type(G)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hDvf3nm-ors4"},"source":["# Visualize the graph\n","nx.draw(G, with_labels = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FX25Y1CrYmgN"},"source":["## Question 1: What is the average degree of the karate club network? (5 Points)  \n","问题1：空手道俱乐部网络的平均度数是多少？ (5 分)"]},{"cell_type":"code","metadata":{"id":"AUhES1VYo3tB"},"source":["def average_degree(num_edges, num_nodes):\n","  # TODO: Implement this function that takes number of edges\n","  # and number of nodes, and returns the average node degree of \n","  # the graph. Round the result to nearest integer (for example \n","  # 3.3 will be rounded to 3 and 3.7 will be rounded to 4)\n","  # 实现此函数，该函数采用边数和节点数，并返回图的平均节点度。 将结果四舍五入到最接近的整数（例如 3.3 将四舍五入为 3，3.7 将四舍五入为 4）\n","\n","  avg_degree = 0\n","\n","  ############# Your code here ############\n","  '''\n","  if (num_edges / num_nodes) - int(num_edges / num_nodes) > 0.5:\n","      avg_degree = int(num_edges / num_nodes) + 1\n","  else:\n","      avg_degree = int(num_edges / num_nodes)\n","  '''\n","  avg_degree = 2*num_edges / num_nodes\n","  avg_degree = round(avg_degree, 0)\n","  #########################################\n","\n","  return avg_degree\n","\n","num_edges = G.number_of_edges()\n","num_nodes = G.number_of_nodes()\n","avg_degree = average_degree(num_edges, num_nodes)\n","print(\"Average degree of karate club network is {}\".format(avg_degree))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fk02fD4vYmZI"},"source":["## Question 2: What is the average clustering coefficient of the karate club network? (5 Points)  \n","问题2：空手道俱乐部网络的平均聚类系数是多少？ (5 分)"]},{"cell_type":"code","metadata":{"id":"k15XKEto1aYJ"},"source":["def average_clustering_coefficient(G):\n","  # TODO: Implement this function that takes a nx.Graph\n","  # and returns the average clustering coefficient. Round \n","  # the result to 2 decimal places (for example 3.333 will\n","  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n","\n","  avg_cluster_coef = 0\n","\n","  ############# Your code here ############\n","  ## Note: \n","  ## 1: Please use the appropriate NetworkX clustering function\n","  num_nodes = G.number_of_nodes()\n","  avg_cluster_coef = nx.average_clustering(G, nodes=None, weight=None, count_zeros=True)\n","  # print(avg_cluster_coef)\n","  '''\n","  if avg_cluster_coef*1000%5 > 1:\n","      avg_cluster_coef = int((avg_cluster_coef*100 + 1))/100\n","  else:\n","      avg_cluster_coef = int(avg_cluster_coef*100)/100\n","  '''\n","  avg_cluster_coef = round(avg_cluster_coef, 2)\n","  #########################################\n","\n","  return avg_cluster_coef\n","\n","avg_cluster_coef = average_clustering_coefficient(G)\n","print(\"Average clustering coefficient of karate club network is {}\".format(avg_cluster_coef))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zghQ-AhXYmP4"},"source":["## Question 3: What is the PageRank value for node 0 (node with id 0) after one PageRank iteration? (5 Points)\n","问题 3：经过一次 PageRank 迭代后，节点 0（id 为 0 的节点）的 PageRank 值是多少？ (5 分)\n","\n","Please complete the code block by implementing the PageRank equation:  \n","请通过实现 PageRank 方程来完成代码块：  \n"," $r_j = \\sum_{i \\rightarrow j} \\beta \\frac{r_i}{d_i} + (1 - \\beta) \\frac{1}{N}$"]},{"cell_type":"code","metadata":{"id":"BOGdWjNc6O7x"},"source":["def one_iter_pagerank(G, beta, r0, node_id):\n","  # TODO: Implement this function that takes a nx.Graph, beta, r0 and node id.\n","  # The return value r1 is one interation PageRank value for the input node.\n","  # Please round r1 to 2 decimal places.\n","\n","  r1 = 0\n","\n","  ############# Your code here ############\n","  ## Note: \n","  ## 1: You should not use nx.pagerank\n","  #得到node0的邻居→得到这些邻居的出度（是无向图，所以就是度数）→计算得到右式中的第一项（\\sum{i→j}\\beta\\frac{r_i}{d_i}）→计算得到r_j\n","  for ni in nx.neighbors(G,node_id):\n","      #得到的每一个ni都是node0邻居的索引，参考：https://networkx.org/documentation/stable/reference/generated/networkx.classes.function.neighbors.html\n","      #另一种获取节点邻居的方式是访问邻接矩阵，参考该博文notes部分：https://www.neusncp.com/user/blog?id=38\n","      di=G.degree[ni]  #获取node_ni的度数\n","      r1 += beta*float(r0/di)\n","  r1 +=  (1-beta)*r0\n","  print(r1)  \n","  r1 = round(r1, 2)\n","  '''\n","  pagerank_list = nx.pagerank(G, alpha=1)\n","  # print(pagerank_list)\n","  r1 = round(pagerank_list[node_id],2)\n","  '''\n","  #########################################\n","\n","  return r1\n","\n","beta = 0.8\n","r0 = 1 / G.number_of_nodes()\n","node = 0\n","r1 = one_iter_pagerank(G, beta, r0, node)\n","print(\"The PageRank value for node 0 after one iteration is {}\".format(r1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"icTcOULeYmIu"},"source":["## Question 4: What is the (raw) closeness centrality for the karate club network node 5? (5 Points)  \n","空手道俱乐部网络节点 5 的（原始）接近中心性是什么？ (5 分)\n","\n","The equation for closeness centrality is 接近中心性的方程是 $c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{shortest path length between } u \\text{ and } v}$"]},{"cell_type":"code","metadata":{"id":"XbCsq_tl-3ok"},"source":["def closeness_centrality(G, node=5):\n","  # TODO: Implement the function that calculates closeness centrality \n","  # for a node in karate club network. G is the input karate club \n","  # network and node is the node id in the graph. Please round the \n","  # closeness centrality result to 2 decimal places.\n","\n","  closeness = 0\n","\n","  ## Note:\n","  ## 1: You can use networkx closeness centrality function.\n","  ## 2: Notice that networkx closeness centrality returns the normalized \n","  ## closeness directly, which is different from the raw (unnormalized) \n","  ## one that we learned in the lecture.\n","  '''\n","    node_length_pairs=nx.shortest_path_length(G,source=5)\n","    #返回字典，key是节点索引，value是source与该节点间的最短路径长度\n","\n","    denominator=0  #分母\n","    for i in range(G.number_of_nodes()):\n","    if i!=5:  #其实不用这个判断也行，如果i=5就会是0\n","        denominator+=node_length_pairs[i]\n","    closeness=round(1/denominator,2)\n","  '''\n","  \n","  closeness = nx.closeness_centrality(G,u=node) # 函数是原始closeness centrality做了规范化（乘以 (图节点数量-1) ）\n","  closeness=closeness/(G.number_of_nodes()-1)\n","  closeness = round(closeness, 2)\n","  #########################################[node]\n","\n","  return closeness\n","\n","node = 5\n","closeness = closeness_centrality(G, node=node)\n","print(\"The karate club network has closeness centrality {}\".format(closeness))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-MxvowibYl4x"},"source":["# 2 Graph to Tensor\n","We will then work together to transform the graph $G$ into a PyTorch tensor, so that we can perform machine learning over the graph.\n","然后我们将共同将图 G 转换为 PyTorch 张量，以便我们可以对图执行机器学习。"]},{"cell_type":"markdown","metadata":{"id":"eDA8PosrA-9V"},"source":["## Setup\n","Check if PyTorch is properly installed"]},{"cell_type":"code","metadata":{"id":"ntuPVat_BAf1"},"source":["import torch\n","print(torch.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fko_2wSKYlun"},"source":["## PyTorch tensor basics\n","\n","We can generate PyTorch tensor with all zeros, ones or random values.  \n","我们可以生成全为零、一或随机值的 PyTorch 张量。"]},{"cell_type":"code","metadata":{"id":"W2ySw3m-A9qF"},"source":["# Generate 3 x 4 tensor with all ones\n","ones = torch.ones(3, 4)\n","print(ones)\n","\n","# Generate 3 x 4 tensor with all zeros\n","zeros = torch.zeros(3, 4)\n","print(zeros)\n","\n","# Generate 3 x 4 tensor with random values on the interval [0, 1)\n","random_tensor = torch.rand(3, 4)\n","print(random_tensor)\n","\n","# Get the shape of the tensor\n","print(ones.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x8mp66eHBxWC"},"source":["PyTorch tensor contains elements for a single data type, the `dtype`.  \n","PyTorch 张量包含单一数据类型 dtype 的元素。"]},{"cell_type":"code","metadata":{"id":"rQiOvKJJBwq4"},"source":["# Create a 3 x 4 tensor with all 32-bit floating point zeros\n","zeros = torch.zeros(3, 4, dtype=torch.float32)\n","print(zeros.dtype)\n","\n","# Change the tensor dtype to 64-bit integer\n","zeros = zeros.type(torch.long)\n","print(zeros.dtype)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I9EfegIRDkk2"},"source":["## Question 5: Getting the edge list of the karate club network and transform it into `torch.LongTensor`. What is the `torch.sum` value of `pos_edge_index` tensor? (10 Points)  \n","问题5：获取空手道俱乐部网络的边缘列表，并转化为torch.LongTensor。 pos_edge_index 张量的 torch.sum 值是多少？ （10分）"]},{"cell_type":"code","metadata":{"id":"kEtVxMFID3ZT"},"source":["def graph_to_edge_list(G):\n","  # TODO: Implement the function that returns the edge list of\n","  # an nx.Graph. The returned edge_list should be a list of tuples\n","  # where each tuple is a tuple representing an edge connected \n","  # by two nodes.\n","\n","  edge_list = []\n","\n","  ############# Your code here ############\n","  for edge in G.edges():\n","      edge_list.append(edge)\n","  #########################################\n","\n","  return edge_list\n","\n","def edge_list_to_tensor(edge_list):\n","  # TODO: Implement the function that transforms the edge_list to\n","  # tensor. The input edge_list is a list of tuples and the resulting\n","  # tensor should have the shape [2 x len(edge_list)].\n","\n","  edge_index = torch.tensor([])\n","\n","  ############# Your code here ############\n","  edge_index = torch.LongTensor(edge_list).t()\n","  # edge_index = torch.tensor(edge_list).transpose(1, 0)\n","  #########################################\n","\n","  return edge_index\n","\n","pos_edge_list = graph_to_edge_list(G)\n","pos_edge_index = edge_list_to_tensor(pos_edge_list)\n","print(\"The pos_edge_index tensor has shape {}\".format(pos_edge_index.shape))\n","print(\"The pos_edge_index tensor has sum value {}\".format(torch.sum(pos_edge_index)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UBL-ZmdHWqIu"},"source":["## Question 6: Please implement following function that samples negative edges. Then you will answer which edges (edge_1 to edge_5) can be negative ones in the karate club network? (10 Points)  \n","问题 6：请实现以下对负边缘进行采样的函数。 然后你会回答空手道俱乐部网络中哪些边（edge_1 到 edge_5）可以是负的？ （10分）"]},{"cell_type":"code","metadata":{"id":"9N8VT1f8-IJ8"},"source":["import random\n","\n","def sample_negative_edges(G, num_neg_samples):\n","  # TODO: Implement the function that returns a list of negative edges.\n","  # The number of sampled negative edges is num_neg_samples. You do not\n","  # need to consider the corner case when the number of possible negative edges\n","  # is less than num_neg_samples. It should be ok as long as your implementation \n","  # works on the karate club network. In this implementation, self loop should \n","  # not be considered as either a positive or negative edge. Also, notice that \n","  # the karate club network is an undirected graph, if (0, 1) is a positive \n","  # edge, do you think (1, 0) can be a negative one?\n","\n","  neg_edge_list = []\n","\n","  ############# Your code here ############\n","  #得到图中所有不存在的边（这个函数只会返回一侧，不会出现逆边）\n","  non_edges_one_side=list(enumerate(nx.non_edges(G)))\n","  neg_edge_list_indices=random.sample(range(0,len(non_edges_one_side)),num_neg_samples)  #取样num_neg_samples长度的索引\n","  #抽取逻辑是按照non_edges_one_side的索引来抽取边\n","  for i in neg_edge_list_indices:\n","    neg_edge_list.append(non_edges_one_side[i][1])\n","  #########################################\n","\n","  return neg_edge_list\n","\n","# Sample 78 negative edges\n","neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n","\n","# Transform the negative edge list to tensor\n","neg_edge_index = edge_list_to_tensor(neg_edge_list)\n","print(\"The neg_edge_index tensor has shape {}\".format(neg_edge_index.shape))\n","\n","# Which of following edges can be negative ones?\n","edge_1 = (7, 1)\n","edge_2 = (1, 33)\n","edge_3 = (33, 22)\n","edge_4 = (0, 4)\n","edge_5 = (4, 2)\n","\n","############# Your code here ############\n","## Note:\n","## 1: For each of the 5 edges, print whether it can be negative edge\n","#如果边在图中，就认为不行\n","print('edge_1'+(\" can't\" if G.has_edge(edge_1[0],edge_1[1]) else ' can')+' be negative edge')\n","print('edge_2'+(\" can't\" if G.has_edge(edge_2[0],edge_2[1]) else ' can')+' be negative edge')\n","print('edge_3'+(\" can't\" if G.has_edge(edge_3[0],edge_3[1]) else ' can')+' be negative edge')\n","print('edge_4'+(\" can't\" if G.has_edge(edge_4[0],edge_4[1]) else ' can')+' be negative edge')\n","print('edge_5'+(\" can't\" if G.has_edge(edge_5[0],edge_5[1]) else ' can')+' be negative edge')\n","#########################################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wk9Q-a-9qGsw"},"source":["# 3 Node Emebedding Learning\n","\n","Finally, we will finish the first learning algorithm on graphs: a node embedding model.  \n","最后，我们将完成第一个图学习算法：节点嵌入模型。\n"]},{"cell_type":"markdown","metadata":{"id":"NDBxRQcZ_dUH"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"Lnqn9H6s_ehX"},"source":["import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","\n","print(torch.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6gomAf8vxq0R"},"source":["To write our own node embedding learning methods, we'll heavily use the [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) module in PyTorch. Let's see how to use `nn.Embedding`:  \n","为了编写我们自己的节点嵌入学习方法，我们将大量使用 PyTorch 中的 nn.Embedding 模块。 让我们看看如何使用 nn.Embedding："]},{"cell_type":"code","metadata":{"id":"aRiWGuLAx5yx"},"source":["# Initialize an embedding layer\n","# Suppose we want to have embedding for 4 items (e.g., nodes)\n","# Each item is represented with 8 dimensional vector\n","\n","emb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\n","print('Sample embedding layer: {}'.format(emb_sample))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bS9qQfeujEVh"},"source":["We can select items from the embedding matrix, by using Tensor   \n","我们可以通过使用张量索引从嵌入矩阵中选择项目"]},{"cell_type":"code","metadata":{"id":"9AGIfP4QEDr8"},"source":["# Select an embedding in emb_sample\n","id = torch.LongTensor([1])\n","print(emb_sample(id))\n","\n","# Select multiple embeddings\n","ids = torch.LongTensor([1, 3])\n","print(emb_sample(ids))\n","\n","# Get the shape of the embedding weight matrix\n","shape = emb_sample.weight.data.shape\n","print(shape)\n","\n","# Overwrite the weight to tensor with all ones\n","emb_sample.weight.data = torch.ones(shape)\n","print(emb_sample.weight.data)\n","\n","# Let's check if the emb is indeed initilized\n","ids = torch.LongTensor([0, 3])\n","print(emb_sample(ids))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8MjBuDKaKIsM"},"source":["Now, it's your time to create node embedding matrix for the graph we have!  \n","现在，是时候为我们拥有的图形创建节点嵌入矩阵了！\n","- We want to have **16 dimensional** vector for each node in the karate club network.  \n","我们希望空手道俱乐部网络中的每个节点都有 16 维向量。\n","- We want to initalize the matrix under **uniform distribution**, in the range of $[0, 1)$. We suggest you using [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html).  \n","我们想在均匀分布下初始化矩阵，在 [0,1) 的范围内。 我们建议您使用 torch.rand。"]},{"cell_type":"code","metadata":{"id":"hMszSwRPKGn1"},"source":["# Please do not change / reset the random seed\n","torch.manual_seed(1)\n","\n","def create_node_emb(num_node=34, embedding_dim=16):\n","  # TODO: Implement this function that will create the node embedding matrix.\n","  # A torch.nn.Embedding layer will be returned. You do not need to change \n","  # the values of num_node and embedding_dim. The weight matrix of returned \n","  # layer should be initialized under uniform distribution. \n","\n","  emb = None\n","\n","  ############# Your code here ############\n","  emb = nn.Embedding(num_embeddings=num_node, embedding_dim=embedding_dim)\n","  #Embedding初始化本来就是均匀分布。不过在这里应该是要用manual_seed来维持可复现性\n","  emb.weight.data=torch.rand(num_node,embedding_dim)\n","  #########################################\n","\n","  return emb\n","\n","emb = create_node_emb()\n","ids = torch.LongTensor([0, 3])\n","\n","# Print the embedding layer\n","print(\"Embedding: {}\".format(emb))\n","\n","# An example that gets the embeddings for node 0 and 3\n","print(emb(ids))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4QfoANibTzyh"},"source":["## Visualize the initial node embeddings\n","One good way to understand an embedding matrix, is to visualize it in a 2D space.\n","Here, we have implemented an embedding visualization function for you.\n","We first do PCA to reduce the dimensionality of embeddings to a 2D space.\n","Then visualize each point, colored by the community it belongs to.  \n","理解嵌入矩阵的一种好方法是在 2D 空间中对其进行可视化。 在这里，我们为您实现了嵌入可视化功能。 我们首先进行 PCA 以将嵌入的维度降低到 2D 空间。 然后可视化每个点，由它所属的社区着色。"]},{"cell_type":"code","metadata":{"id":"_LCoIkarhfYD"},"source":["def visualize_emb(emb):\n","  X = emb.weight.data.numpy()\n","  pca = PCA(n_components=2)\n","  components = pca.fit_transform(X)\n","  plt.figure(figsize=(6, 6))\n","  club1_x = []\n","  club1_y = []\n","  club2_x = []\n","  club2_y = []\n","  for node in G.nodes(data=True):\n","    if node[1]['club'] == 'Mr. Hi':\n","      club1_x.append(components[node[0]][0])\n","      club1_y.append(components[node[0]][1])\n","    else:\n","      club2_x.append(components[node[0]][0])\n","      club2_y.append(components[node[0]][1])\n","  plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n","  plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n","  plt.legend()\n","  plt.show()\n","\n","# Visualize the initial random embeddding\n","visualize_emb(emb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bQIyuEz9ANb2"},"source":["## Question 7: Training the embedding! What is the best performance you can get? Please report both the best loss and accuracy on Gradescope. (20 Points)  \n","问题 7：训练嵌入！ 您可以获得的最佳性能是什么？ 请在 Gradescope 上报告最佳损失和准确度。 (20 分)"]},{"cell_type":"code","metadata":{"id":"RDeQTNNxqH0j"},"source":["from torch.optim import SGD\n","\n","def accuracy(pred, label):\n","  # TODO: Implement the accuracy function. This function takes the \n","  # pred tensor (the resulting tensor after sigmoid) and the label \n","  # tensor (torch.LongTensor). Predicted value greater than 0.5 will \n","  # be classified as label 1. Else it will be classified as label 0.\n","  # The returned accuracy should be rounded to 4 decimal places. \n","  # For example, accuracy 0.82956 will be rounded to 0.8296.\n","\n","  accu = 0.0\n","\n","  ############# Your code here ############\n","  #accuracy=预测与实际一致的结果数/所有结果数\n","  #pred tensor和label tensor都是[78*2(156)]大小的tensor\n","  pred = pred > 0.5\n","  accu = (pred==label).sum().item() / (pred.shape[0])\n","  accu = round(accu,4)\n","  #########################################\n","\n","  return accu\n","\n","def train(emb, loss_fn, sigmoid, train_label, train_edge):\n","  # TODO: Train the embedding layer here. You can also change epochs and \n","  # learning rate. In general, you need to implement: \n","  # (1) Get the embeddings of the nodes in train_edge\n","  # (2) Dot product the embeddings between each node pair\n","  # (3) Feed the dot product result into sigmoid\n","  # (4) Feed the sigmoid output into the loss_fn\n","  # (5) Print both loss and accuracy of each epoch \n","  # (as a sanity check, the loss should decrease during training)\n","\n","  epochs = 500\n","  learning_rate = 0.1\n","\n","  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n","\n","  for i in range(epochs):\n","    ############# Your code here ############\n","    optimizer.zero_grad()\n","    train_node_emb = emb(train_edge)  #[2,156,16]\n","    dot_product_result = train_node_emb[0].mul(train_node_emb[1])  #点对之间对应位置嵌入相乘，[156,16]\n","    dot_product_result = torch.sum(dot_product_result,1)  #加起来，构成点对之间向量的点积，[156]\n","    sigmoid_result = sigmoid(dot_product_result)  #将这个点积结果经过激活函数映射到0,1之间\n","    loss_result = loss_fn(sigmoid_result,train_label)\n","    loss_result.backward()\n","    optimizer.step()\n","    if i%10 == 0:  #其实这个应该每一轮都打印一遍的，但是我嫌太大了就十轮打印一遍了\n","      print(loss_result)\n","      print(accuracy(sigmoid_result,train_label))\n","    #########################################\n","\n","loss_fn = nn.BCELoss()\n","sigmoid = nn.Sigmoid()\n","\n","# Generate the positive and negative labels\n","pos_label = torch.ones(pos_edge_index.shape[1], )\n","neg_label = torch.zeros(neg_edge_index.shape[1], )\n","\n","# Concat positive and negative labels into one tensor\n","train_label = torch.cat([pos_label, neg_label], dim=0)\n","\n","# Concat positive and negative edges into one tensor\n","# Since the network is very small, we do not split the edges into val/test sets\n","train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n","\n","train(emb, loss_fn, sigmoid, train_label, train_edge)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WX2PSXnTDiNi"},"source":["## Visualize the final node embeddings\n","Visualize your final embedding here! \n","You can visually compare the figure with the previous embedding figure. \n","After training, you should oberserve that the two classes are more evidently separated. \n","This is a great sanitity check for your implementation as well.  \n","在此处可视化您的最终嵌入！ 您可以直观地将图与之前的嵌入图进行比较。 训练后，您应该观察到两个类的分离更加明显。 这对您的实施也是一个很好的健全性检查。"]},{"cell_type":"code","metadata":{"id":"MtNgl4VhYKow"},"source":["# Visualize the final learned embedding\n","visualize_emb(emb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FTNyrAoSVeq9"},"source":["# Submission"]},{"cell_type":"markdown","metadata":{"id":"E_E7J_GkVhY_"},"source":["In order to get credit, you must go submit your answers on Gradescope."]}]}